{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initial file upload: TMDB_tv_dataset_v3.csv"
      ],
      "metadata": {
        "id": "fZlUCRtcH96r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LN_iaoT76TBx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(r\"TMDB_tv_dataset_v3.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SxsJyvJV9OF"
      },
      "outputs": [],
      "source": [
        "import matplotlib as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sb\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgAi5R50FiJg"
      },
      "source": [
        "# Step 1: Data Preparation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TXgCen6rJWm"
      },
      "outputs": [],
      "source": [
        "# To have an overview of the dataset\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To have an overview of missing data and types of data\n",
        "\n",
        "# ניצור טבלת סיכום מקיפה לכל עמודה\n",
        "summary = pd.DataFrame({\n",
        "    'non_null_count': df.notnull().sum(),\n",
        "    'null_percent': df.isnull().mean() * 100,\n",
        "    'num_unique': df.nunique(),\n",
        "    'data_type': df.dtypes,\n",
        "}).sort_values(by='null_percent', ascending=False)\n",
        "\n",
        "print(summary)"
      ],
      "metadata": {
        "id": "7NuiQixDECp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "_zA19Qp-EQxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDRQH24EtAFo"
      },
      "outputs": [],
      "source": [
        "# Show all columns\n",
        "pd.set_option('display.max_columns', None)\n",
        "print(df.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdmbMkl9cftB"
      },
      "source": [
        "## Look at rows and columns - Rows and columns duplication, check nulls and unknown - to\n",
        "\n",
        "---\n",
        "\n",
        "remove them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZ9f2oPAiyEE"
      },
      "outputs": [],
      "source": [
        "# חיפוש עמודות זהות - לא נמצאו\n",
        "# To see columns with duplicate content - Didn't find any!\n",
        "# יצירת רשימה לאחסון זוגות עמודות עם תוכן כפול\n",
        "duplicate_content = []\n",
        "\n",
        "# לולאה על כל זוגות עמודות\n",
        "for i in range(len(df.columns)):\n",
        "    for j in range(i+1, len(df.columns)):\n",
        "        col1 = df.columns[i]\n",
        "        col2 = df.columns[j]\n",
        "        if df[col1].equals(df[col2]):\n",
        "            duplicate_content.append((col1, col2))\n",
        "\n",
        "print(\"Columns with duplicate content:\", duplicate_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRVNYotC3J63"
      },
      "outputs": [],
      "source": [
        "# Screen for duplication whole row - by three parameters: id, name, original_name\n",
        "# חיפוש שורות עם אותו id, name, original_name - נמצאו ובהמשך נמחק אחד מהם\n",
        "# לפי שלושת הפרמטרים האלה כי זה חוסך זמן הרצה\n",
        "# ----------------------------\n",
        "# חלק 1 – בדיקה והצגת כפילויות\n",
        "# ----------------------------\n",
        "\n",
        "# 1️⃣ מציאת כל השורות הכפולות לפי עמודות ספציפיות\n",
        "duplicate_rows = df[df.duplicated(subset=['id', 'name', 'original_name'], keep=False)]\n",
        "\n",
        "# 2️⃣ מיון התוצאות כדי שיהיה קל לראות את הכפילויות\n",
        "duplicate_rows = duplicate_rows.sort_values(by=['id', 'name', 'original_name'])\n",
        "\n",
        "# 3️⃣ הצגת 10 דוגמאות ראשונות של כפילויות\n",
        "print(\"דוגמאות של כפילויות:\")\n",
        "print(duplicate_rows.head(10))\n",
        "\n",
        "# 4️⃣ הדפסת מספר השורות הכולל שמזוהות ככפולות\n",
        "num_duplicates = len(duplicate_rows)\n",
        "print(f\"\\nנמצאו {num_duplicates} שורות כפולות (כולל כל העותקים).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkh3Rs0n1c1s"
      },
      "outputs": [],
      "source": [
        "# חלק 2 – הסרת כל הכפילויות\n",
        "\n",
        "# Combine repeated rows into one - New df copy for this process: df_unique\n",
        "\n",
        "# מספר השורות המקורי\n",
        "original_rows = len(df)\n",
        "\n",
        "# ----------------------------\n",
        "# הסרת כל הכפילויות, שמירה על מופע אחד לכל שילוב של ['id', 'name', 'original_name']\n",
        "# ----------------------------\n",
        "df_unique = df.drop_duplicates(subset=['id', 'name', 'original_name']).reset_index(drop=True)\n",
        "\n",
        "# חישוב מספר השורות הלא ייחודיות שהוסרו\n",
        "removed_rows = original_rows - len(df_unique)\n",
        "\n",
        "# הצגה מהירה של התוצאה\n",
        "print(\"\\nתוצאות לאחר הסרת כפילויות:\")\n",
        "print(df_unique.head())\n",
        "print(f\"סה\\\"כ שורות ייחודיות: {len(df_unique)}\")\n",
        "print(f\"סה\\\"כ שורות לא ייחודיות שנמחקו: {removed_rows}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw1ZOFp4BI00"
      },
      "source": [
        "# New data file name: df_unique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3y-cCjmxsZU"
      },
      "outputs": [],
      "source": [
        "print(f\"מספר העמודות: {len(df_unique.columns)}\")\n",
        "print(\"שמות העמודות:\")\n",
        "print(df_unique.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explore target - popularity"
      ],
      "metadata": {
        "id": "--xH91qNE2NF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUvpFNGoTEj9"
      },
      "outputs": [],
      "source": [
        "df_unique['popularity'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x=np.log1p(df['popularity']))  # נתונים מופיעים על ציר X\n",
        "plt.title('Boxplot of log(Popularity) - Horizontal', fontsize=14, weight='bold')\n",
        "plt.xlabel('log(Popularity + 1)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LsaTzhPtFEGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# לא שייך לכאן!!!!!!!!!!!!!!!1\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# אם אין עדיין עמודת קטגוריה, אפשר ליצור:\n",
        "labels = ['Low', 'Mid', 'Hit']\n",
        "df['popularity_3cat'] = pd.qcut(df['popularity'], q=3, labels=labels)\n",
        "\n",
        "# יוצרים עמודת לוגריתם זמנית\n",
        "df['log_popularity'] = np.log1p(df['popularity'])\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x='log_popularity', y='popularity_3cat', data=df, palette='Set2')\n",
        "plt.title('Boxplot of log(Popularity) by Category', fontsize=14, weight='bold')\n",
        "plt.xlabel('log(Popularity + 1)')\n",
        "plt.ylabel('Popularity Category')\n",
        "plt.show()\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "f3r1YjCfMBhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df['popularity'], bins=30, kde=True, color='skyblue')\n",
        "plt.title('Histogram of Popularity', fontsize=14, weight='bold')\n",
        "plt.xlabel('Popularity')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "g7TNCzZNMIJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(np.log1p(df['popularity']), bins=30, kde=True, color='skyblue')\n",
        "plt.title('Histogram of log(Popularity + 1)', fontsize=14, weight='bold')\n",
        "plt.xlabel('log(Popularity + 1)')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6-mXBMxVMOHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pop_max = df['popularity'].quantile(0.99)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df[df['popularity'] <= pop_max]['popularity'], bins=30, kde=True, color='skyblue')\n",
        "plt.title('Histogram of Popularity (99th percentile)', fontsize=14, weight='bold')\n",
        "plt.xlabel('Popularity')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nPT3__4wMUlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOsBLwNvTewp"
      },
      "outputs": [],
      "source": [
        "# Check overall nulls\n",
        "import missingno as msno\n",
        "msno.matrix(df_unique)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-Ir-CC6SThm"
      },
      "outputs": [],
      "source": [
        "# Checking nulls by percentage\n",
        "missing_percent = df_unique.isnull().mean() * 100\n",
        "print(missing_percent.sort_values(ascending=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pTsx6Gs1dC-"
      },
      "source": [
        "# Repeated columns with the same information\n",
        "## Columns handeling - unit or remove duplicate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tw4nRLp77vel"
      },
      "outputs": [],
      "source": [
        "# Repeated columns with the same information\n",
        "# Second - TV show name and original name\n",
        "\n",
        "print(df_unique[['name', 'original_name']].head(20))\n",
        "\n",
        "different_rows = df_unique[df_unique['name'] != df_unique['original_name']]\n",
        "print(different_rows[['name', 'original_name']].head(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ybKVniG0RNC"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Coulmns 'name' and 'original_name' - are mostly the same.\n",
        "# Check for missing values in 'name' column - without the name the row is useless\n",
        "# ספירת שורות שבהן 'name' חסר\n",
        "\n",
        "# מציאת השורות שבהן 'name' חסר\n",
        "missing_name_rows = df_unique[df_unique['name'].isnull()]\n",
        "missing_name_count = len(missing_name_rows)\n",
        "\n",
        "print(f\"מספר השורות שבהן 'name' חסר: {missing_name_count}\")\n",
        "missing_name_rows[['id', 'name', 'original_name']].head(20)  # תצוגה לדוגמה\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbCsQrh7L-_6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# הגדרת תנאי לחסר אמיתי בשם:\n",
        "# 1. name הוא NaN\n",
        "# 2. name הוא ריק (\"\")\n",
        "# 3. name מכיל רק נקודות, כמו \"...\" או \".....\"\n",
        "missing_name_condition = (\n",
        "    df_unique['name'].isna() |\n",
        "    (df_unique['name'].astype(str).str.strip() == \"\") |\n",
        "    (df_unique['name'].astype(str).str.match(r'^\\.*$'))\n",
        ")\n",
        "\n",
        "# שליפת השורות החסרות לפי התנאי\n",
        "missing_name_rows = df_unique[missing_name_condition]\n",
        "\n",
        "print(f\"מספר השורות שבהן name חסר או בעייתי: {len(missing_name_rows)}\")\n",
        "missing_name_rows[['id', 'name', 'original_name']].head(20)  # תצוגה לדוגמה\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvJ3NwLtNNov"
      },
      "outputs": [],
      "source": [
        "# מספר שורות לפני המחיקה\n",
        "rows_before = len(df_unique)\n",
        "print(f\"סה\\\"כ שורות לפני המחיקה: {rows_before}\")\n",
        "\n",
        "# תנאי לזיהוי name לא תקין: NaN, ריק, או רק נקודות\n",
        "missing_name_condition = (\n",
        "    df_unique['name'].isna() |\n",
        "    (df_unique['name'].astype(str).str.strip() == \"\") |\n",
        "    (df_unique['name'].astype(str).str.match(r'^\\.*$'))\n",
        ")\n",
        "\n",
        "# שמירת השורות למחיקה (לצפייה או שמירה)\n",
        "missing_name_rows = df_unique[missing_name_condition]\n",
        "deleted_ids = missing_name_rows['id'].tolist()\n",
        "\n",
        "# מחיקת השורות הלא תקינות\n",
        "df_unique = df_unique[~missing_name_condition].reset_index(drop=True)\n",
        "\n",
        "# מספר שורות אחרי המחיקה\n",
        "rows_after = len(df_unique)\n",
        "print(f\"סה\\\"כ שורות אחרי המחיקה: {rows_after}\")\n",
        "\n",
        "# כמה שורות נמחקו\n",
        "removed_rows = rows_before - rows_after\n",
        "print(f\"סה\\\"כ שורות שנמחקו: {removed_rows}\")\n",
        "\n",
        "# הצגת ה-ID שנמחקו\n",
        "print(\"ID של השורות שנמחקו בגלל name לא תקין:\")\n",
        "print(deleted_ids)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSKK8Zra78Lc"
      },
      "outputs": [],
      "source": [
        "# מיזוג עמודות של 'name' ו 'original_name' לעמודה חדשה שנקראת 'final_name' ומחיקת שתי העמודות המקוריות\n",
        "import re\n",
        "\n",
        "# --- פונקציה למיזוג שמות ---\n",
        "def merge_names(row):\n",
        "    name = row['name']\n",
        "    original = row['original_name']\n",
        "\n",
        "    if pd.isna(name) and pd.isna(original):\n",
        "        return None\n",
        "    elif pd.isna(name):\n",
        "        return original\n",
        "    elif pd.isna(original):\n",
        "        return name\n",
        "    elif name == original:\n",
        "        return name\n",
        "    else:\n",
        "        return f\"{name} / {original}\"\n",
        "\n",
        "# --- יוצרים את העמודה המאוחדת ---\n",
        "df_unique['final_name'] = df_unique.apply(merge_names, axis=1)\n",
        "\n",
        "# --- ניקוי ושיפוץ ה-final_name ---\n",
        "df_unique['final_name'] = df_unique['final_name'].str.strip()                             # הסרת רווחים מיותרים\n",
        "df_unique['final_name'] = df_unique['final_name'].str.lower()                             # המרה לאותיות קטנות\n",
        "df_unique['final_name'] = df_unique['final_name'].str.replace(r'[^\\w\\s]', '', regex=True)  # הסרת תווים מיוחדים\n",
        "\n",
        "# --- המרת העמודה לסוג string של pandas ---\n",
        "df_unique['final_name'] = df_unique['final_name'].astype('string')\n",
        "\n",
        "# --- מחיקת העמודות המקוריות ---\n",
        "df_unique = df_unique.drop(columns=['name', 'original_name'])\n",
        "\n",
        "# --- בדיקה של 20 השורות הראשונות ---\n",
        "print(df_unique[['final_name']].head(20))\n",
        "\n",
        "# --- בדיקת סוג הנתונים ---\n",
        "print(\"\\nData type of final_name:\", df_unique['final_name'].dtype)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27GSfuRGJvSK"
      },
      "source": [
        "# Repeated columns with the same information\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wm-SzgSKAxgX"
      },
      "outputs": [],
      "source": [
        "# Repeated columns with the same information\n",
        "# First - take a look at language\n",
        "\n",
        "# מציג את חמש השורות הראשונות של העמודות הרצויות\n",
        "print(df_unique[['original_language', 'languages', 'origin_country',\n",
        "                 'spoken_languages', 'production_countries']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtXjp-PBFsQP"
      },
      "outputs": [],
      "source": [
        "# Check language uniques\n",
        "language_columns = ['original_language', 'languages', 'origin_country',\n",
        "                    'spoken_languages', 'production_countries']\n",
        "\n",
        "for col in language_columns:\n",
        "    print(f\"\\n--- {col} ---\")\n",
        "    print(df_unique[col].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxN_HfQCEpWE"
      },
      "outputs": [],
      "source": [
        "### Remove column!!\n",
        "# Leave only one language column - \"original_language\", and remove the others.... Dont' remove the 'production_countries'\n",
        "\n",
        "# רשימת העמודות לשפה שאנחנו רוצים למחוק\n",
        "cols_to_drop = ['languages', 'origin_country', 'spoken_languages']\n",
        "\n",
        "# מוחק את העמודות האלו\n",
        "df_unique = df_unique.drop(columns=cols_to_drop)\n",
        "\n",
        "# בודק את העמודות שנותרו\n",
        "print(df_unique.columns)\n",
        "\n",
        "# בודק כמה שורות נשארו\n",
        "print(df_unique.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Columns with more then 50% missing values"
      ],
      "metadata": {
        "id": "agmx8XZZHHWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Columns with more then 50% missing data - nulls.\n",
        "\n",
        "# חישוב אחוז השורות החסרות בכל עמודה\n",
        "missing_percent = df_unique.isnull().mean() * 100\n",
        "\n",
        "# בחירת העמודות עם 50% או יותר חסר\n",
        "columns_50pct_or_more_missing = missing_percent[missing_percent >= 50].index.tolist()\n",
        "\n",
        "# הצגת התוצאה\n",
        "print(\"עמודות עם יותר או שווה ל-50% ערכים חסרים:\")\n",
        "print(columns_50pct_or_more_missing)\n"
      ],
      "metadata": {
        "id": "qEIeoHrRHGYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# הצגת 10 שורות ראשונות רק מהעמודות עם יותר מ-50% חסר\n",
        "# חישוב אחוז השורות החסרות בכל עמודה\n",
        "missing_percent = df_unique[columns_50pct_or_more_missing].isnull().mean() * 100\n",
        "\n",
        "# יצירת DataFrame חדש עם כותרות מותאמות: שם העמודה + אחוז ה-NULLs\n",
        "df_to_show = df_unique[columns_50pct_or_more_missing].head(10).copy()\n",
        "df_to_show.columns = [f\"{col} ({missing_percent[col]:.1f}% NULLs)\" for col in df_to_show.columns]\n",
        "\n",
        "# הצגת 10 השורות הראשונות עם הכותרות החדשות\n",
        "print(\"\\n10 השורות הראשונות מהעמודות עם יותר או שווה ל-50% ערכים חסרים (כולל אחוז NULLs):\")\n",
        "print(df_to_show)\n",
        "\n"
      ],
      "metadata": {
        "id": "alza6nqxHYy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove columns with more then 50% nulls, leave the 'production_countries' for furter analysis .\n",
        "\n",
        "\n",
        "# חישוב אחוז השורות החסרות בכל עמודה\n",
        "missing_percent = df_unique.isnull().mean() * 100\n",
        "\n",
        "# בחירת העמודות עם 50% או יותר חסר\n",
        "columns_50pct_or_more_missing = missing_percent[missing_percent >= 50].index.tolist()\n",
        "\n",
        "# הסרת 'production_countries' מהרשימה (לא למחוק אותה)\n",
        "columns_to_drop = [col for col in columns_50pct_or_more_missing if col != 'production_countries']\n",
        "\n",
        "# הורדת העמודות\n",
        "df_unique = df_unique.drop(columns=columns_to_drop)\n",
        "\n",
        "# הצגת העמודות שנותרו\n",
        "print(\"העמודות אחרי המחיקה (כולל production_countries):\")\n",
        "print(df_unique.columns.tolist())\n"
      ],
      "metadata": {
        "id": "u1rwae1LHhmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check overall nulls\n",
        "import missingno as msno\n",
        "msno.matrix(df_unique)\n",
        "\n",
        "# בודק את העמודות שנותרו\n",
        "print(df_unique.columns)\n",
        "\n",
        "# בודק כמה שורות נשארו\n",
        "print(df_unique.shape)"
      ],
      "metadata": {
        "id": "i0Fk-57KHoiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCn8vJhPJ7Uu"
      },
      "source": [
        "# Deal with \"dates\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9v6IyYakrh2h"
      },
      "outputs": [],
      "source": [
        "# Deal with \"dates\".\n",
        "\n",
        "# ---  המרת עמודות תאריכים ל-datetime ---\n",
        "df_unique['first_air_date'] = pd.to_datetime(df_unique['first_air_date'], errors='coerce')\n",
        "df_unique['last_air_date'] = pd.to_datetime(df_unique['last_air_date'], errors='coerce')\n",
        "\n",
        "# ---  חליצה של תכונות שימושיות ---\n",
        "\n",
        "# שנה, חודש, יום של התאריך הראשון\n",
        "df_unique['first_year'] = df_unique['first_air_date'].dt.year\n",
        "df_unique['first_month'] = df_unique['first_air_date'].dt.month\n",
        "df_unique['first_day'] = df_unique['first_air_date'].dt.day\n",
        "\n",
        "# שנה, חודש, יום של התאריך האחרון\n",
        "df_unique['last_year'] = df_unique['last_air_date'].dt.year\n",
        "df_unique['last_month'] = df_unique['last_air_date'].dt.month\n",
        "df_unique['last_day'] = df_unique['last_air_date'].dt.day\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6xEUsHRRwAB"
      },
      "outputs": [],
      "source": [
        "# עבור תאריכים - נעשה עמודה חדשה\n",
        "# production_length\n",
        "# ונשאיר רק את first_year ו last_year\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# נניח שכבר קיימות NaN במקום ערכים חסרים\n",
        "# חישוב production_length עם NaN\n",
        "df_unique['production_length'] = df_unique['last_year'] - df_unique['first_year']\n",
        "\n",
        "# החלפת כל ה-NaN ב-production_length ב- -1\n",
        "df_unique['production_length'] = df_unique['production_length'].fillna(-1)\n",
        "\n",
        "# אפשר גם להחליף NaN בעצמות העמודות אם רוצים\n",
        "df_unique['first_year'] = df_unique['first_year'].fillna(-1)\n",
        "df_unique['last_year']  = df_unique['last_year'].fillna(-1)\n",
        "\n",
        "# מחיקת העמודות המיותרות\n",
        "cols_to_drop = ['first_month', 'first_day', 'last_month', 'last_day', 'first_air_date', 'last_air_date']\n",
        "df_unique = df_unique.drop(columns=[col for col in cols_to_drop if col in df_unique.columns])\n",
        "\n",
        "# בדיקה\n",
        "df_unique[['first_year', 'last_year', 'production_length']].head(10)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDyrYbRASRAV"
      },
      "outputs": [],
      "source": [
        "msno.matrix(df_unique)\n",
        "df_unique.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove uninformative column 'poster_path'"
      ],
      "metadata": {
        "id": "hNPbcB8KILLm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKeQbIKM9OXN"
      },
      "outputs": [],
      "source": [
        "# עמודה שנשארה והיא לא אינפורמטיבית שנוציא אותה\n",
        "# מחיקת העמודה 'poster_path'\n",
        "df_unique = df_unique.drop(columns=['poster_path'])\n",
        "\n",
        "# הצגת רשימת העמודות אחרי המחיקה\n",
        "print(\"רשימת העמודות אחרי מחיקה:\")\n",
        "print(df_unique.columns.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UifSIbk-sJ_a"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ניצור טבלת סיכום מקיפה לכל עמודה\n",
        "summary = pd.DataFrame({\n",
        "    'non_null_count': df_unique.notnull().sum(),\n",
        "    'null_percent': df_unique.isnull().mean() * 100,\n",
        "    'num_unique': df_unique.nunique(),\n",
        "    'data_type': df_unique.dtypes,\n",
        "}).sort_values(by='null_percent', ascending=False)\n",
        "\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4FPsf62cryI"
      },
      "source": [
        "# Try to nerrow uniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUDD5Hh4KOcK"
      },
      "outputs": [],
      "source": [
        "# ערכים ייחודיים בכל עמודה\n",
        "# רשימת העמודות\n",
        "columns_to_check = ['type', 'in_production', 'genres', 'status', 'production_countries', 'networks', 'overview']\n",
        "\n",
        "# הדפסה מסודרת של הערכים הייחודיים עם שם העמודה\n",
        "for col in columns_to_check:\n",
        "    print(f\"ערכים ייחודיים בעמודה '{col}':\")\n",
        "    print(df_unique[col].unique())\n",
        "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "\n",
        "# מספר הערכים הייחודיים\n",
        "print(\"Number of unique values in 'type':\", df_unique['type'].nunique())\n",
        "print(\"Number of unique values in 'in_production':\", df_unique['in_production'].nunique())\n",
        "print(\"Number of unique values in 'genres':\", df_unique['genres'].nunique())\n",
        "print(\"Number of unique values in 'status':\", df_unique['status'].nunique())\n",
        "print(\"Number of unique values in 'production_countries':\", df_unique['production_countries'].nunique())\n",
        "print(\"Number of unique values in 'networks':\", df_unique['networks'].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdC-NMN6U3Ez"
      },
      "outputs": [],
      "source": [
        "# Show all columns\n",
        "pd.set_option('display.max_columns', None)\n",
        "print(df_unique.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5yRcOYtElDG"
      },
      "outputs": [],
      "source": [
        "# clean text for editing: remove spaces, capital letters...\n",
        "# בחירת כל העמודות הטקסטואליות\n",
        "text_cols = df_unique.select_dtypes(include=['object', 'string']).columns.tolist()\n",
        "print(\"עמודות טקסטואליות לניקוי:\", text_cols)\n",
        "\n",
        "# פונקציה לניקוי מחרוזות\n",
        "def clean_text(val):\n",
        "    if pd.isnull(val):\n",
        "        return val  # להשאיר NaN כפי שהוא\n",
        "    val = str(val).strip().lower()  # הסרת רווחים והמרה לאותיות קטנות\n",
        "    # ניקוי רווחים סביב פסיקים (לערכים שמופרדים בפסיקים)\n",
        "    val = ','.join([v.strip() for v in val.split(',')])\n",
        "    return val\n",
        "\n",
        "# מחיקת פסיקים מיותרים ורווחים והמרה לאותיות קטנות לכל העמודות הטקסטואליות\n",
        "for col in text_cols:\n",
        "    df_unique[col] = df_unique[col].apply(clean_text)\n",
        "\n",
        "# הצגת דוגמה 10 השורות הראשונות אחרי הניקוי\n",
        "print(df_unique[text_cols].head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wn1xCDCeX_RJ"
      },
      "outputs": [],
      "source": [
        "# Look for uniques in columns: 'production_countries' and 'networks'\n",
        "# ערכים ייחודיים בכל עמודה\n",
        "print(df_unique['production_countries'].unique())\n",
        "print(df_unique['networks'].unique())\n",
        "\n",
        "# מספר הערכים הייחודיים\n",
        "\n",
        "print(\"Number of unique values in 'production_countries':\", df_unique['production_countries'].nunique())\n",
        "print(\"Number of unique values in 'networks':\", df_unique['networks'].nunique())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSTYGfQTfxwx"
      },
      "outputs": [],
      "source": [
        "# Look for uniques in column: 'episode_run_time'\n",
        "\n",
        "df_unique['episode_run_time'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCRhEkkgiDoM"
      },
      "outputs": [],
      "source": [
        "# Max and Min uniques values in 'episode_run_time'\n",
        "# מקסימום ומינימום של הערכים הייחודיים\n",
        "unique_times = df_unique['episode_run_time'].dropna().unique()\n",
        "min_time = unique_times.min() if hasattr(unique_times, 'min') else min(unique_times)\n",
        "max_time = unique_times.max() if hasattr(unique_times, 'max') else max(unique_times)\n",
        "\n",
        "print(f\"Minimum episode run time: {min_time} minutes\")\n",
        "print(f\"Maximum episode run time: {max_time} minutes\")\n",
        "\n",
        "# ספירה של הערכים 0\n",
        "num_zeros = (df_unique['episode_run_time'] == 0).sum()\n",
        "print(f\"Number of 0 values in episode_run_time: {num_zeros}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkcvqFk9x0-s"
      },
      "outputs": [],
      "source": [
        "# Check df\n",
        "summary = pd.DataFrame({\n",
        "    'null_percent': df_unique.isnull().mean() * 100,\n",
        "    'num_unique': df_unique.nunique(),\n",
        "    'data_type': df_unique.dtypes\n",
        "}).sort_values(by='null_percent', ascending=False)\n",
        "\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xDxqgv4yn65"
      },
      "source": [
        "## Changing strings/objects into category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGpFXafL0ix6"
      },
      "outputs": [],
      "source": [
        "# Lets start with the easy columns that have short limitied uniques\n",
        "categorical_cols = ['original_language', 'type', 'status', 'production_countries', 'networks', 'genres']\n",
        "for col in categorical_cols:\n",
        "    df_unique[col] = df_unique[col].astype('category')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_6fxfroAawx"
      },
      "outputs": [],
      "source": [
        "summary = pd.DataFrame({\n",
        "    'null_percent': df_unique.isnull().mean() * 100,\n",
        "    'num_unique': df_unique.nunique(),\n",
        "    'data_type': df_unique.dtypes\n",
        "}).sort_values(by='null_percent', ascending=False)\n",
        "\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxJSwzCdO_qi"
      },
      "outputs": [],
      "source": [
        "df_unique['production_countries'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7si7XdNRr8n"
      },
      "outputs": [],
      "source": [
        "# A better overview of 'production_countries' uniques\n",
        "\n",
        "# מאפשר הדפסת כל הערכים בעמודות ללא קיצוץ\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# סופרים את מספר ההופעות של כל ערך בעמודה production_countries\n",
        "value_counts = df_unique['production_countries'].value_counts()\n",
        "\n",
        "# הופך את זה ל-DataFrame להצגה מסודרת\n",
        "value_counts_df = value_counts.reset_index()\n",
        "value_counts_df.columns = ['production_countries', 'count']\n",
        "\n",
        "# מציג את כל הערכים עם מספר ההופעות\n",
        "print(value_counts_df)\n",
        "\n",
        "# בסיום, אפשר להחזיר להגדרות ברירת המחדל\n",
        "pd.reset_option('display.max_rows')\n",
        "pd.reset_option('display.max_columns')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGmOw0ieBAUV"
      },
      "outputs": [],
      "source": [
        "# Uniques in 'type'\n",
        "df_unique['type'].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zowpMZzMHUF"
      },
      "outputs": [],
      "source": [
        "# Uniques in 'status'\n",
        "\n",
        "df_unique['status'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEjQHM-aB34V"
      },
      "outputs": [],
      "source": [
        "# A better overview of 'original_language' uniques\n",
        "\n",
        "# מאפשר הדפסת כל הערכים בעמודות ללא קיצוץ\n",
        "pd.set_option('display.max_rows', None)  # מציג כל השורות\n",
        "pd.set_option('display.max_columns', None)  # מציג כל העמודות\n",
        "\n",
        "# מציג את כל הערכים ושכיחויות\n",
        "print(df_unique['original_language'].value_counts())\n",
        "\n",
        "# בסיום, אפשר להחזיר להגדרות ברירת המחדל\n",
        "# pd.reset_option('display.max_rows')\n",
        "# pd.reset_option('display.max_columns')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPCs2GMAZNt5"
      },
      "outputs": [],
      "source": [
        "# Unit 'original_language' uniques that are under 10 counts\n",
        "\n",
        "# שפות מתחת ל 10 הפכו להיות OTHER\n",
        "# עבור original_language\n",
        "\n",
        "# 1️⃣ ניקוי רווחים ותווים מיותרים בעמודת השפה\n",
        "df_unique['original_language'] = df_unique['original_language'].astype(str).str.strip().str.lower()\n",
        "\n",
        "# 2️⃣ ספירת כל הערכים בעמודה\n",
        "language_counts = df_unique['original_language'].value_counts()\n",
        "\n",
        "# 3️⃣ זיהוי שפות שמופיעות פחות מ-10 פעמים\n",
        "rare_languages = language_counts[language_counts < 10].index\n",
        "\n",
        "# 4️⃣ החלפה של הערכים הנדירים ב-'other' ישירות בעמודה הקיימת\n",
        "df_unique['original_language'] = df_unique['original_language'].apply(\n",
        "    lambda x: 'other' if x in rare_languages else x\n",
        ")\n",
        "\n",
        "# 5️⃣ הצגת התוצאות\n",
        "print(\"התפלגות השפות לאחר איחוד ערכים נדירים:\")\n",
        "print(df_unique['original_language'].value_counts().sort_values(ascending=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-roXx3CCLnR"
      },
      "outputs": [],
      "source": [
        "# A better overview of 'overview' uniques\n",
        "\n",
        "df_unique['overview'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldEE5tHoE4Wb"
      },
      "outputs": [],
      "source": [
        "# Clean text - spaces and other - in 'overview. For further editing\n",
        "df_unique['overview'] = df_unique['overview'].apply(\n",
        "    lambda x: x.strip().lower() if isinstance(x, str) else x\n",
        ")\n",
        "print(df_unique['overview'].head(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmPu4dbAFyin"
      },
      "outputs": [],
      "source": [
        "# Check results\n",
        "df_unique['networks'].value_counts()\n",
        "print(df_unique['networks'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxGpBnhh-Wrw"
      },
      "outputs": [],
      "source": [
        "# # A better overview of 'networks' uniques\n",
        "\n",
        "# מאפשר הדפסת כל הערכים בעמודות ללא קיצוץ\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# סופרים את מספר ההופעות של כל ערך בעמודה networks\n",
        "value_counts = df_unique['networks'].value_counts()\n",
        "\n",
        "# הופכים ל-DataFrame עם עמודות: שם הרשת ומספר ההופעות\n",
        "value_counts_df = value_counts.reset_index()\n",
        "value_counts_df.columns = ['network', 'count']\n",
        "\n",
        "# מציגים את כל הערכים עם מספר ההופעות\n",
        "print(value_counts_df)\n",
        "\n",
        "# בסיום, אפשר להחזיר להגדרות ברירת המחדל\n",
        "pd.reset_option('display.max_rows')\n",
        "pd.reset_option('display.max_columns')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZ9ZP1Fz_p65"
      },
      "outputs": [],
      "source": [
        "# Unit 'networks' uniques that are under 10 counts\n",
        "\n",
        "# 1️⃣ סופרים את מספר ההופעות של כל רשת\n",
        "network_counts = df_unique['networks'].value_counts()\n",
        "\n",
        "# 2️⃣ מזהים את הערכים שמופיעים פחות מ-10 פעמים\n",
        "rare_networks = network_counts[network_counts < 10].index.tolist()\n",
        "\n",
        "# 3️⃣ מחליפים את הערכים הנדירים ב-'OTHER'\n",
        "df_unique['networks'] = df_unique['networks'].apply(lambda x: 'OTHER' if x in rare_networks else x)\n",
        "\n",
        "# 4️⃣ בדיקה: השכיחויות לאחר האיחוד\n",
        "print(\"שכיחויות הערכים לאחר איחוד נדירים ל-OTHER:\")\n",
        "print(df_unique['networks'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctN3BLIQF2OI"
      },
      "outputs": [],
      "source": [
        "# Explore 'genres' uniques\n",
        "\n",
        "df_unique['genres'].value_counts()\n",
        "print(df_unique['genres'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lxn-hF8wG_Iq"
      },
      "outputs": [],
      "source": [
        "# explore 'genres' unique and clean spaces... for futher editing\n",
        "# ניקוי ואיחוד ז'אנרים ותיאור אחיד של מילים\n",
        "# פונקציה לניקוי ולמיון הז'אנרים\n",
        "def clean_genres(val):\n",
        "    if pd.isna(val) or val.strip() == '':\n",
        "        return val\n",
        "    # פיצול לפי פסיקים, הסרת רווחים, המרה לאותיות קטנות\n",
        "    items = [x.strip().lower() for x in val.split(',')]\n",
        "    items.sort()  # מיון אלפביתי\n",
        "    return ','.join(items)  # חיבור חזרה\n",
        "\n",
        "# יישום הפונקציה על כל העמודה הקיימת\n",
        "df_unique['genres'] = df_unique['genres'].apply(clean_genres)\n",
        "\n",
        "# הצגת השכיחויות של הערכים לאחר הניקוי\n",
        "print(df_unique['genres'].value_counts().head(100))\n",
        "\n",
        "# סיכום: כמה ערכים ייחודיים עכשיו בעמודה\n",
        "num_unique_genres = df_unique['genres'].nunique()\n",
        "print(f\"\\nסה\\\"כ ערכים ייחודיים בעמודה 'genres' לאחר הניקוי: {num_unique_genres}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rR_xbRer7Fyg"
      },
      "outputs": [],
      "source": [
        "# Unit 'genres' uniques that are under 10 counts\n",
        "\n",
        "# 1️⃣ ספירת כל הערכים בעמודת genres\n",
        "counts = df_unique['genres'].value_counts()\n",
        "\n",
        "# 2️⃣ זיהוי הערכים שמופיעים פחות מ-10 פעמים\n",
        "to_replace = counts[counts < 10].index.tolist()\n",
        "\n",
        "# 3️⃣ החלפת הערכים הנדירים ב-'other'\n",
        "df_unique['genres'] = df_unique['genres'].apply(\n",
        "    lambda x: 'other' if x in to_replace else x\n",
        ")\n",
        "\n",
        "# 4️⃣ בדיקה: הצגת ההתפלגות לאחר האיחוד\n",
        "value_counts = df_unique['genres'].value_counts()\n",
        "print(value_counts)\n",
        "\n",
        "# 5️⃣ הצגת סיכום מספר הערכים הייחודיים לאחר האיחוד\n",
        "print(f\"\\nסה\\\"כ ערכים ייחודיים בעמודה 'genres' לאחר האיחוד: {df_unique['genres'].nunique()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jc6Eqk9D68ol"
      },
      "outputs": [],
      "source": [
        "# To have an overview of missing data and types of data\n",
        "\n",
        "# ניצור טבלת סיכום מקיפה לכל עמודה\n",
        "summary = pd.DataFrame({\n",
        "    'non_null_count': df_unique.notnull().sum(),\n",
        "    'null_percent': df_unique.isnull().mean() * 100,\n",
        "    'num_unique': df_unique.nunique(),\n",
        "    'data_type': df_unique.dtypes,\n",
        "}).sort_values(by='null_percent', ascending=False)\n",
        "\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnyzDdlLJomP"
      },
      "outputs": [],
      "source": [
        "# רשימת העמודות שיישמרו כ-object\n",
        "keep_object = ['overview', 'final_name']\n",
        "\n",
        "# המרה של כל שאר העמודות מסוג object ל-category\n",
        "for col in df_unique.select_dtypes(include=['object']).columns:\n",
        "    if col not in keep_object:\n",
        "        df_unique[col] = df_unique[col].astype('category')\n",
        "\n",
        "# בדיקה\n",
        "# ניצור טבלת סיכום מקיפה לכל עמודה\n",
        "summary = pd.DataFrame({\n",
        "    'non_null_count': df_unique.notnull().sum(),\n",
        "    'null_percent': df_unique.isnull().mean() * 100,\n",
        "    'num_unique': df_unique.nunique(),\n",
        "    'data_type': df_unique.dtypes,\n",
        "}).sort_values(by='null_percent', ascending=False)\n",
        "\n",
        "print(summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8Nb_td4MlUi"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cD6rQzzmQSVg"
      },
      "outputs": [],
      "source": [
        "!pip install autoviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1bRuaQQR5bJ"
      },
      "outputs": [],
      "source": [
        "!pip install textblob\n",
        "!python -m textblob.download_corpora\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EDA reports"
      ],
      "metadata": {
        "id": "OtI94kptRYbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AutoViz report - Popularity as Target\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "from autoviz.AutoViz_Class import AutoViz_Class\n",
        "\n",
        "AV = AutoViz_Class()\n",
        "\n",
        "df_auto = AV.AutoViz(\n",
        "    filename=\"\",\n",
        "    dfte=df_unique,\n",
        "    depVar=\"popularity\",\n",
        "    sep=\",\",\n",
        "    chart_format=\"png\",   # תומך יותר מכל\n",
        "    max_rows_analyzed=30000,\n",
        "    verbose=2             # מציג מידע נוסף בהרצה\n",
        ")\n"
      ],
      "metadata": {
        "id": "fq1dFqWTTK4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ydata-profiling report\n",
        "\n",
        "# התקנה (אם טרם הותקן)\n",
        "!pip install ydata-profiling --quiet\n",
        "\n",
        "# ייבוא הספרייה\n",
        "from ydata_profiling import ProfileReport\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "KafU3JKoSXNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# יצירת דו\"ח\n",
        "profile = ProfileReport(df_unique, title=\"EDA Report - Dataset Overview\", explorative=True)\n",
        "\n",
        "# להצגה ישירה במחברת (Jupyter / Colab)\n",
        "profile.to_notebook_iframe()\n",
        "\n",
        "# או לשמירה לקובץ HTML\n",
        "profile.to_file(\"EDA_report.html\")\n",
        "\n",
        "print(\"✅ דו\\\"ח EDA נוצר ונשמר כ-'EDA_report.html'\")\n"
      ],
      "metadata": {
        "id": "-YZsH9hRSgMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "profile.to_file(\"EDA_report.html\")"
      ],
      "metadata": {
        "id": "j8EGWauPSszu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files\n",
        "files.download(\"EDA_report.html\")"
      ],
      "metadata": {
        "id": "h1Sg5GjBSvBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPbwRZbfog2_"
      },
      "source": [
        "# Data cleansing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErRu-Td0okCD"
      },
      "outputs": [],
      "source": [
        "# Dealing with missing values\n",
        "# ניצור טבלת סיכום מקיפה לכל עמודה\n",
        "summary = pd.DataFrame({\n",
        "    'non_null_count': df_unique.notnull().sum(),\n",
        "    'null_percent': df_unique.isnull().mean() * 100,\n",
        "    'num_unique': df_unique.nunique(),\n",
        "    'data_type': df_unique.dtypes,\n",
        "}).sort_values(by='null_percent', ascending=False)\n",
        "\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfzQdO6vz_Fq"
      },
      "outputs": [],
      "source": [
        "!pip install fancyimpute"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MICE - to fill missing values in 'overview'\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from fancyimpute import IterativeImputer\n",
        "\n",
        "# -----------------------------\n",
        "# 0️⃣ מילוי חוסרים ב-overview\n",
        "# -----------------------------\n",
        "# ממלא NaN\n",
        "df_unique['overview'] = df_unique['overview'].fillna(\"unknown\")\n",
        "# מסיר רווחים וממירה לאותיות קטנות\n",
        "df_unique['overview'] = df_unique['overview'].apply(lambda x: x.strip().lower() if isinstance(x, str) else x)\n",
        "# ממלא מחרוזות ריקות ב-\"unknown\"\n",
        "df_unique.loc[df_unique['overview'] == \"\", 'overview'] = \"unknown\"\n",
        "\n",
        "# -----------------------------\n",
        "# 1️⃣ יצירת TF-IDF מה-overview (למטרת MICE בלבד)\n",
        "# -----------------------------\n",
        "vectorizer = TfidfVectorizer(max_features=100)\n",
        "overview_tfidf = vectorizer.fit_transform(df_unique['overview']).toarray()\n",
        "overview_df = pd.DataFrame(overview_tfidf, columns=[f\"word_{i}\" for i in range(overview_tfidf.shape[1])])\n",
        "\n",
        "# -----------------------------\n",
        "# 2️⃣ המרת קטגוריות ל-numeric\n",
        "# -----------------------------\n",
        "categorical_cols = ['genres', 'networks', 'production_countries', 'type', 'status', 'adult']\n",
        "le_dict = {}\n",
        "\n",
        "for col in categorical_cols:\n",
        "    if pd.api.types.is_categorical_dtype(df_unique[col]):\n",
        "        df_unique[col] = df_unique[col].cat.add_categories([\"Unknown\"])\n",
        "    df_unique[col] = df_unique[col].fillna(\"Unknown\")\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    df_unique[col] = le.fit_transform(df_unique[col])\n",
        "    le_dict[col] = le\n",
        "\n",
        "# -----------------------------\n",
        "# 3️⃣ הכנת דאטה ל-MICE (numeric בלבד + TF-IDF)\n",
        "#    ✅ הוצאת id כדי לא לפגוע ב-MICE\n",
        "# -----------------------------\n",
        "numeric_cols = df_unique.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "numeric_cols = [col for col in numeric_cols if col != 'id']  # <-- כאן הוספנו את התיקון\n",
        "\n",
        "df_for_mice = pd.concat([df_unique[numeric_cols], overview_df], axis=1)\n",
        "\n",
        "# -----------------------------\n",
        "# 4️⃣ ריצת MICE\n",
        "# -----------------------------\n",
        "imp = IterativeImputer(max_iter=10, random_state=0)\n",
        "df_filled_array = imp.fit_transform(df_for_mice)\n",
        "df_filled = pd.DataFrame(df_filled_array, columns=df_for_mice.columns)\n",
        "\n",
        "# -----------------------------\n",
        "# 5️⃣ החזרת קטגוריות למצב טקסט\n",
        "# -----------------------------\n",
        "for col in categorical_cols:\n",
        "    le = le_dict[col]\n",
        "    df_filled[col] = df_filled[col].round().astype(int)\n",
        "    df_filled[col] = le.inverse_transform(df_filled[col])\n",
        "\n",
        "# -----------------------------\n",
        "# 6️⃣ החזרת overview המקורי (שכבר מלא בהשלמות)\n",
        "# -----------------------------\n",
        "df_filled['overview'] = df_unique['overview']\n",
        "\n",
        "# -----------------------------\n",
        "# 7️⃣ מחיקת עמודות TF-IDF\n",
        "# -----------------------------\n",
        "tfidf_cols = [col for col in df_filled.columns if col.startswith(\"word_\")]\n",
        "df_filled.drop(columns=tfidf_cols, inplace=True)\n",
        "\n",
        "# -----------------------------\n",
        "# 8️⃣ החזרת כל העמודות הטקסטואליות המקוריות שלא עברו MICE\n",
        "# -----------------------------\n",
        "non_numeric_cols = df_unique.select_dtypes(exclude=['int64', 'float64']).columns.tolist()\n",
        "for col in non_numeric_cols:\n",
        "    if col != 'overview':  # overview כבר הוספנו\n",
        "        df_filled[col] = df_unique[col]\n",
        "\n",
        "# -----------------------------\n",
        "# ✅ החזרת עמודת id כמו שהיא\n",
        "# -----------------------------\n",
        "df_filled['id'] = df_unique['id']\n",
        "\n",
        "# -----------------------------\n",
        "# 9️⃣ בדיקה\n",
        "# -----------------------------\n",
        "print(\"מספר ערכים חסרים אחרי כל התהליך:\")\n",
        "print(df_filled.isnull().sum())\n"
      ],
      "metadata": {
        "id": "tQBublNhw3Vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUgRSPl6p59w"
      },
      "source": [
        "# new dataframe - df_filled"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# File check\n",
        "df_filled.info()"
      ],
      "metadata": {
        "id": "nia0g39rYXN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "df_filled.to_csv('df_new_GitHub.csv', index=False)\n",
        "files.download('df_new_GitHub.csv')\n",
        "\n"
      ],
      "metadata": {
        "id": "B_hWSssmC7ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Continue in second file"
      ],
      "metadata": {
        "id": "7unU-tC9ZGOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For GitHub upload\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Lw8dx-2HkoxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nbformat\n",
        "\n",
        "# Path ל-notebook הנוכחי\n",
        "path = '/content/drive/MyDrive/Project TV show popularity/advance project/More advanced project/For GitHub/Upload to GitHub/GitHub_1_TV_show_popularity_part_one_upload.ipynb'  # שנה לפי הנתיב שלך\n",
        "\n",
        "\n",
        "\n",
        "# קריאה ועריכה של ה-notebook\n",
        "nb = nbformat.read(path, as_version=4)\n",
        "\n",
        "# ניקוי metadata בעייתית\n",
        "if \"widgets\" in nb.metadata:\n",
        "    del nb.metadata[\"widgets\"]\n",
        "if \"colab\" in nb.metadata:\n",
        "    del nb.metadata[\"colab\"]\n",
        "if \"celltoolbar\" in nb.metadata:\n",
        "    del nb.metadata[\"celltoolbar\"]\n",
        "\n",
        "# שמירה מחדש\n",
        "nbformat.write(nb, path)\n",
        "print(\"✅ Notebook cleaned and ready for GitHub!\")"
      ],
      "metadata": {
        "id": "fEGwXlOMkvs0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}